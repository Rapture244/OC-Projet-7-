{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Database Implementation",
   "id": "9bb5e2b47d8a608"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-30T13:52:25.198891Z",
     "start_time": "2025-01-30T13:52:25.116411Z"
    }
   },
   "source": [
    "# == MAGIC COMMANDS ====================================================================================================\n",
    "# Enable matplotlib to display graphs directly in the notebook.\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the autoreload extension to automatically reload external Python modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Set the precision of floating point numbers displayed in output for better readability\n",
    "%precision 4\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'%.4f'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:52:26.260442Z",
     "start_time": "2025-01-30T13:52:26.187774Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---- Standard Library Imports ----\n",
    "import warnings\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "\n",
    "# ---- Third-Party Library Imports ----\n",
    "from loguru import logger\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Project-Specific Imports ----\n",
    "from prod.utils import load_csv, check_full_system_environment\n",
    "from prod.paths import DATABASE_DIR, RAW_DATA_DIR, PROCESSED_DATA_DIR, API_STATIC_DIR\n",
    "\n",
    "\n",
    "# Filters\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ],
   "id": "3707beb42c2c2f8",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T12:57:46.366405Z",
     "start_time": "2025-01-30T12:57:46.220736Z"
    }
   },
   "cell_type": "code",
   "source": "check_full_system_environment()",
   "id": "4f1da33e8b22f61",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-01-30 13:57:46.283\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m72\u001B[0m - \u001B[1mStarting comprehensive system and GPU environment checks...\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.283\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m82\u001B[0m - \u001B[34m\u001B[1mPython Version: 3.12.4\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.283\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m83\u001B[0m - \u001B[34m\u001B[1mOperating System: Windows 10.0.22621\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.283\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m84\u001B[0m - \u001B[34m\u001B[1mArchitecture: AMD64\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.283\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m85\u001B[0m - \u001B[34m\u001B[1mNumber of Processors: 16\n",
      "\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.298\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m92\u001B[0m - \u001B[1mCUDA nvcc output:\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2022 NVIDIA Corporation\n",
      "Built on Mon_Oct_24_19:40:05_Pacific_Daylight_Time_2022\n",
      "Cuda compilation tools, release 12.0, V12.0.76\n",
      "Build cuda_12.0.r12.0/compiler.31968024_0\n",
      "\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m103\u001B[0m - \u001B[1mGPU compute capabilities:\n",
      "NVIDIA T1200 Laptop GPU\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m112\u001B[0m - \u001B[1mStarting OpenCL platform and device enumeration...\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m119\u001B[0m - \u001B[32m\u001B[1m--- Platform #0: NVIDIA CUDA ---\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m120\u001B[0m - \u001B[34m\u001B[1m  Vendor: NVIDIA Corporation\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m121\u001B[0m - \u001B[34m\u001B[1m  Version: OpenCL 3.0 CUDA 12.4.131\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m130\u001B[0m - \u001B[32m\u001B[1m--- Device #0: NVIDIA T1200 Laptop GPU ---\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m131\u001B[0m - \u001B[1m    Type: GPU\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m132\u001B[0m - \u001B[1m    Compute Units: 16\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m133\u001B[0m - \u001B[1m    Global Memory: 4095.69 MB\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m134\u001B[0m - \u001B[1m    Max Clock Frequency: 1560 MHz\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m135\u001B[0m - \u001B[1m    Max Work Group Size: 1024\n",
      "\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m119\u001B[0m - \u001B[32m\u001B[1m--- Platform #1: Intel(R) OpenCL Graphics ---\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m120\u001B[0m - \u001B[34m\u001B[1m  Vendor: Intel(R) Corporation\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m121\u001B[0m - \u001B[34m\u001B[1m  Version: OpenCL 3.0 \u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.346\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m130\u001B[0m - \u001B[32m\u001B[1m--- Device #0: Intel(R) UHD Graphics ---\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.361\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m131\u001B[0m - \u001B[1m    Type: GPU\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.362\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m132\u001B[0m - \u001B[1m    Compute Units: 32\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m133\u001B[0m - \u001B[1m    Global Memory: 12972.65 MB\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m134\u001B[0m - \u001B[1m    Max Clock Frequency: 1450 MHz\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.363\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m135\u001B[0m - \u001B[1m    Max Work Group Size: 512\n",
      "\u001B[0m\n",
      "\u001B[32m2025-01-30 13:57:46.364\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mcheck_full_system_environment\u001B[0m:\u001B[36m141\u001B[0m - \u001B[32m\u001B[1mComprehensive system and GPU environment checks completed successfully.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Setting up the database",
   "id": "4810f8f64285faf7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:52:28.763153Z",
     "start_time": "2025-01-30T13:52:28.690585Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Ensure the database directory exists\n",
    "DATABASE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define the database file path\n",
    "DB_PATH: Path = DATABASE_DIR / \"credit_scoring.sqlite\"\n",
    "\n",
    "# Create the database (or connect if it exists)\n",
    "conn: sqlite3.Connection = sqlite3.connect(DB_PATH)\n",
    "conn.close()"
   ],
   "id": "c868a457514ba43d",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Exporting the .csv to the .db",
   "id": "8193e7e9c46631fc"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The raw customer data",
   "id": "8c44551abf2d90c7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:52:42.182915Z",
     "start_time": "2025-01-30T13:52:40.598488Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset that will be sent to the database\n",
    "df_raw: pd.DataFrame = load_csv(file_name = \"application_test.csv\", parent_path = RAW_DATA_DIR)\n",
    "\n",
    "# Connect to the database\n",
    "conn: sqlite3.Connection = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Store dataset in SQLite as a table\n",
    "df_raw.to_sql(name=\"customer_data\", con=conn, if_exists=\"replace\", index = False)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ],
   "id": "daf9d2adf7eadcba",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-01-30 14:52:41.038\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mload_csv\u001B[0m:\u001B[36m206\u001B[0m - \u001B[1mLoaded     application_test.csv                     Shape:     (48744, 121)         Encoding:  ascii\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### The data used by our model",
   "id": "db1e01ae7ca5b4c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:52:46.047055Z",
     "start_time": "2025-01-30T13:52:45.082505Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset that will be sent to the database\n",
    "df_predict: pd.DataFrame = load_csv(file_name = \"04_prediction_df.csv\", parent_path = PROCESSED_DATA_DIR)\n",
    "\n",
    "# Connect to the database\n",
    "conn: sqlite3.Connection = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Store dataset in SQLite as a table\n",
    "df_predict.to_sql(name=\"model_input_data\", con=conn, if_exists=\"replace\", index = False)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ],
   "id": "bd52fdb35925d242",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-01-30 14:52:45.433\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mload_csv\u001B[0m:\u001B[36m206\u001B[0m - \u001B[1mLoaded     04_prediction_df.csv                     Shape:     (48744, 51)          Encoding:  ascii\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Descriptions about the features used by the model",
   "id": "59373428acd6d63"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:52:53.415232Z",
     "start_time": "2025-01-30T13:52:53.329617Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset that will be sent to the database\n",
    "df_description: pd.DataFrame = load_csv(file_name = \"prediction_df_description.csv\", parent_path = PROCESSED_DATA_DIR)\n",
    "\n",
    "# Connect to the database\n",
    "conn: sqlite3.Connection = sqlite3.connect(DB_PATH)\n",
    "\n",
    "# Store dataset in SQLite as a table\n",
    "df_description.to_sql(name=\"model_input_metadata\", con=conn, if_exists=\"replace\", index = False)\n",
    "\n",
    "# Close the database connection\n",
    "conn.close()"
   ],
   "id": "a08ad0086908c537",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-01-30 14:52:53.402\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36mprod.utils\u001B[0m:\u001B[36mload_csv\u001B[0m:\u001B[36m206\u001B[0m - \u001B[1mLoaded     prediction_df_description.csv            Shape:     (51, 2)              Encoding:  ascii\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Database Scripts",
   "id": "df1c5f2e4b2bc638"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T13:52:57.339699Z",
     "start_time": "2025-01-30T13:52:57.267241Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ====================================== GET THE LIST OF TABLES IN THE DATABASE ====================================== #\n",
    "# Connect to the database\n",
    "conn: sqlite3.Connection = sqlite3.connect(DB_PATH)\n",
    "cursor: sqlite3.Cursor = conn.cursor()\n",
    "\n",
    "# Fetch all table names\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Log the tables found\n",
    "logger.info(f\"Tables in database: {[table[0] for table in tables]}\")"
   ],
   "id": "2df8f94f1025fcfb",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-01-30 14:52:57.337\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m14\u001B[0m - \u001B[1mTables in database: ['customer_data', 'model_input_data', 'model_input_metadata']\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T14:23:13.510811Z",
     "start_time": "2025-01-30T14:23:13.421922Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ======================================== GET THE COLUMNS OF A SPECIFIC TABLE ======================================= #\n",
    "# Define the table name to inspect\n",
    "table_name = \"customer_data\"\n",
    "\n",
    "# Connect to the database\n",
    "conn: sqlite3.Connection = sqlite3.connect(DB_PATH)\n",
    "cursor: sqlite3.Cursor = conn.cursor()\n",
    "\n",
    "# Fetch all column names from the specified table\n",
    "cursor.execute(f\"PRAGMA table_info({table_name});\")\n",
    "columns = cursor.fetchall()\n",
    "\n",
    "# Close the connection\n",
    "conn.close()\n",
    "\n",
    "# Log the column names\n",
    "logger.info(f\"Columns in '{table_name}': {[col[1] for col in columns]}\")\n"
   ],
   "id": "211b7a0955c3ee85",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-01-30 15:23:13.507\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m17\u001B[0m - \u001B[1mColumns in 'customer_data': ['SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT', 'AMT_ANNUITY', 'AMT_GOODS_PRICE', 'NAME_TYPE_SUITE', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'OWN_CAR_AGE', 'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'CNT_FAM_MEMBERS', 'REGION_RATING_CLIENT', 'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START', 'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION', 'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION', 'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY', 'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG', 'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG', 'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG', 'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG', 'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG', 'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE', 'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE', 'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE', 'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE', 'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI', 'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI', 'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI', 'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI', 'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE', 'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE', 'EMERGENCYSTATE_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE', 'DAYS_LAST_PHONE_CHANGE', 'FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21', 'AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT', 'AMT_REQ_CREDIT_BUREAU_YEAR']\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Extracting SHAP Explainer object ",
   "id": "cee3fd5fb2395d23"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T18:47:40.175654Z",
     "start_time": "2025-01-30T18:47:38.642475Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import joblib\n",
    "from prod.paths import API_DIR\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "#                                                     CONFIGURATION                                                    #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "# Model Details\n",
    "MODEL_NAME = \"2025-01-17 - LGBMClassifier - business.joblib\"\n",
    "MODEL_PATH = API_DIR / \"models\" / MODEL_NAME\n",
    "THRESHOLD = 0.48\n",
    "\n",
    "# Scaler Details\n",
    "SCALER_NAME = \"2025-01-17 - RobustScaler.joblib\"\n",
    "SCALER_PATH = API_DIR / \"models\" / SCALER_NAME\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "#                                            LOADING MODELS LOCALLY                                                    #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "# Load Model\n",
    "try:\n",
    "    model = joblib.load(MODEL_PATH)\n",
    "    logger.success(f\"Model loaded successfully from {MODEL_PATH}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading model: {e}\")\n",
    "    raise RuntimeError(\"An error occurred while loading the model. Please check the logs.\")\n",
    "\n",
    "# Load Scaler\n",
    "try:\n",
    "    robust_scaler = joblib.load(SCALER_PATH)\n",
    "    logger.success(f\"Scaler loaded successfully from {SCALER_PATH}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading scaler: {e}\")\n",
    "    raise RuntimeError(\"An error occurred while loading the scaler. Please check the logs.\")\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "#                                                     PREPROCESSING                                                    #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "# Apply RobustScaler with PassThrough\n",
    "try:\n",
    "    # Separate numeric and passthrough features\n",
    "    numeric_features = [col for col in df_predict.select_dtypes(include=[\"number\"]).columns if col != \"SK_ID_CURR\"]\n",
    "    passthrough_features = [\"SK_ID_CURR\"]  # Explicit passthrough feature\n",
    "\n",
    "    # Scale only numeric features using the loaded scaler\n",
    "    numeric_scaled = robust_scaler.transform(df_predict[numeric_features])\n",
    "\n",
    "    # Create a DataFrame for scaled numeric columns\n",
    "    numeric_scaled_df = pd.DataFrame(numeric_scaled, columns=numeric_features, index=df_predict.index)\n",
    "\n",
    "    # Combine scaled numeric features with passthrough columns\n",
    "    passthrough_data = df_predict[passthrough_features]        # Keep passthrough columns untouched\n",
    "    dataset_scaled = pd.concat([numeric_scaled_df, passthrough_data], axis=1)\n",
    "    dataset_scaled = dataset_scaled[df_predict.columns]        # Reorder to match the original structure\n",
    "\n",
    "    logger.success(\"Applied RobustScaler to numeric features successfully.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error applying RobustScaler: {e}\")\n",
    "    raise RuntimeError(\"An error occurred while scaling the df_predict. Please check the logs for more details.\")"
   ],
   "id": "4e310c9e94a15d6e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-01-30 19:47:40.004\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m25\u001B[0m - \u001B[32m\u001B[1mModel loaded successfully from C:\\Users\\KDTB0620\\Documents\\Study\\Open Classrooms\\Git Repository\\projet7\\api\\models\\2025-01-17 - LGBMClassifier - business.joblib\u001B[0m\n",
      "\u001B[32m2025-01-30 19:47:40.023\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m33\u001B[0m - \u001B[32m\u001B[1mScaler loaded successfully from C:\\Users\\KDTB0620\\Documents\\Study\\Open Classrooms\\Git Repository\\projet7\\api\\models\\2025-01-17 - RobustScaler.joblib\u001B[0m\n",
      "\u001B[32m2025-01-30 19:47:40.128\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m59\u001B[0m - \u001B[32m\u001B[1mApplied RobustScaler to numeric features successfully.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T18:54:00.388166Z",
     "start_time": "2025-01-30T18:53:59.087051Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import shap\n",
    "\n",
    "# ==================================================================================================================== #\n",
    "#                                          CREATE SHAP EXPLAINER                                                        #\n",
    "# ==================================================================================================================== #\n",
    "\n",
    "try:\n",
    "    logger.info(\"Computing SHAP Explainer...\")\n",
    "\n",
    "    # Ensure we exclude 'SK_ID_CURR' since it's not a feature\n",
    "    features_only = dataset_scaled.drop(columns=[\"SK_ID_CURR\"], errors=\"ignore\")\n",
    "\n",
    "    # Create a SHAP explainer using the trained model\n",
    "    explainer = shap.Explainer(model, features_only)\n",
    "\n",
    "    logger.success(\"SHAP Explainer created successfully.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error computing SHAP Explainer: {e}\")\n",
    "    raise RuntimeError(\"An error occurred while computing the SHAP explainer.\")\n"
   ],
   "id": "9ca48423ced2e605",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-01-30 19:53:59.855\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m8\u001B[0m - \u001B[1mComputing SHAP Explainer...\u001B[0m\n",
      "\u001B[32m2025-01-30 19:54:00.362\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m16\u001B[0m - \u001B[32m\u001B[1mSHAP Explainer created successfully.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-30T19:27:39.438591Z",
     "start_time": "2025-01-30T19:27:39.192604Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define the save path\n",
    "MODEL_PATH = API_DIR / \"models\" / \"shap_explainer.joblib\"\n",
    "\n",
    "try:\n",
    "    logger.info(f\"Saving SHAP Explainer to {MODEL_PATH}...\")\n",
    "\n",
    "    # Save the SHAP explainer\n",
    "    joblib.dump(explainer, MODEL_PATH)\n",
    "\n",
    "    logger.success(f\"SHAP Explainer saved successfully at {MODEL_PATH}\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error saving SHAP Explainer: {e}\")\n",
    "    raise RuntimeError(\"An error occurred while saving the SHAP explainer.\")"
   ],
   "id": "3a03cbd45b3f905a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-01-30 20:27:39.325\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m5\u001B[0m - \u001B[1mSaving SHAP Explainer to C:\\Users\\KDTB0620\\Documents\\Study\\Open Classrooms\\Git Repository\\projet7\\api\\models\\shap_explainer.joblib...\u001B[0m\n",
      "\u001B[32m2025-01-30 20:27:39.435\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m<module>\u001B[0m:\u001B[36m10\u001B[0m - \u001B[32m\u001B[1mSHAP Explainer saved successfully at C:\\Users\\KDTB0620\\Documents\\Study\\Open Classrooms\\Git Repository\\projet7\\api\\models\\shap_explainer.joblib\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==================================================================================================================== #\n",
    "#                                       PRECOMPUTE SHAP GLOBAL FEATURE IMPORTANCE                                      #\n",
    "# ==================================================================================================================== #\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Config\n",
    "OUTPUT_FILE = API_STATIC_DIR / \"model_predictors.png\"\n",
    "\n",
    "try:\n",
    "    if OUTPUT_FILE.exists():\n",
    "        logger.info(f\"The file {OUTPUT_FILE} already exists. Skipping SHAP computation.\")\n",
    "    else:\n",
    "        # Take a sample of 48,000 rows from the scaled dataset\n",
    "        sample_data = dataset_scaled.sample(n=48000, random_state=42)\n",
    "\n",
    "        # Ensure that the sample excludes the target column if present\n",
    "        features_only = sample_data.drop(columns=[\"SK_ID_CURR\"], errors=\"ignore\")\n",
    "\n",
    "        # Create a SHAP explainer for the model\n",
    "        explainer = shap.Explainer(model, features_only)\n",
    "\n",
    "        # Calculate SHAP values for the sample data\n",
    "        shap_values = explainer(features_only, check_additivity=False)\n",
    "\n",
    "        # Generate a beeswarm plot for the top 15 features\n",
    "        plt.figure(figsize=(13, 9))\n",
    "        shap.summary_plot(\n",
    "            shap_values=shap_values,\n",
    "            features=features_only,\n",
    "            plot_type=\"violin\",\n",
    "            max_display=15,\n",
    "            show=False\n",
    "            )\n",
    "\n",
    "        # Add title with increased padding\n",
    "        plt.title(\"Top 15 Model Predictors\", pad=20, fontsize=16)\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot as a .png file in the specified location\n",
    "        plt.savefig(OUTPUT_FILE)\n",
    "        plt.close()  # Close the plot to free memory\n",
    "        logger.success(f\"SHAP beeswarm plot saved successfully at {OUTPUT_FILE}.\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"Error computing SHAP feature impact: {e}\")\n",
    "    raise RuntimeError(\"An error occurred while precomputing SHAP feature impact. Please check the logs.\")\n"
   ],
   "id": "994a8de7dddbffe9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
